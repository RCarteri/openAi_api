{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RCarteri/openAi_api/blob/main/Speak_with_any_PDF_file_PDF_AI_Clone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 4: Talk with any Document - Integrating ChatCompletion API, Embeddings, and Pinecone\n",
        "\n",
        "In this advanced section of our course, we're going to build a highly interactive and intelligent system that lets users 'talk' with any document. Leveraging the capabilities of OpenAI's ChatCompletion API, the semantic understanding of embeddings, we'll create an application that can understand and retrieve information from documents in a conversational manner.\n",
        "\n",
        "## What You Will Learn\n",
        "\n",
        "- **Integration of OpenAI Services**: Understand how to seamlessly integrate various OpenAI services such as ChatCompletion API and Embeddings to create a powerful AI system.\n",
        "- **Pinecone for Vector Searching**: Get acquainted with Pinecone, a vector database perfect for handling complex queries over embeddings, to efficiently index and retrieve document information.\n",
        "- **Natural Language Understanding**: Enhance the system's ability to comprehend and process human language within documents for more natural interactions.\n",
        "- **User Interface for Document Interaction**: Build a user-friendly interface that allows users to upload documents and engage in conversations with the content.\n",
        "- **Conversational Context Management**: Develop strategies to maintain the context of the conversation, ensuring relevant and accurate responses.\n",
        "\n",
        "## Project Objectives\n",
        "\n",
        "By the end of this project, you will have developed a system that can:\n",
        "\n",
        "1. **Interpret Documents**: Analyze and understand the content of various documents through the power of embeddings.\n",
        "2. **Conversational Interface**: Provide users with the ability to ask questions and receive answers as if they were talking to a human expert on the document's content.\n",
        "3. **Contextual Awareness**: Maintain the thread of conversation, taking into account previous interactions and the document's subject matter.\n",
        "4. **Scalable Document Handling**: Efficiently manage and query a large number of documents using Pinecone's vector database capabilities.\n",
        "\n",
        "## Preparation Checklist\n",
        "\n",
        "Before we dive in, make sure you have:\n",
        "\n",
        "- A Google Colab account.\n",
        "- A foundational understanding of Python, APIs, and natural language processing concepts.\n",
        "- An OpenAI API key with access to the ChatCompletion and Embeddings features ([OpenAI](https://platform.openai.com/account/api-keys)).\n",
        "- Familiarity with LangChain and Pinecone services.\n",
        "\n",
        "## Ready to Talk with Documents?\n",
        "\n",
        "We are about to transform how you interact with text-based information. Prepare to build a conversational bridge between users and the vast world of documents!\n",
        "\n",
        "NOTE:\n",
        "\n",
        "Retrieval-augmented generation (RAG) for large language models (LLMs) aims to improve prediction quality by using an external datastore at inference time to build a richer prompt that includes some combination of context, history, and recent/relevant knowledge.\n"
      ],
      "metadata": {
        "id": "vUehOJlORE-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Libraries import"
      ],
      "metadata": {
        "id": "NDlbXftjSHdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTBw517ySLF2",
        "outputId": "f497eff2-dcc2-458e-f351-94f78facea8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.1.1-py3-none-any.whl (217 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.8/217.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 openai-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_EmMwxN9LBg",
        "outputId": "81201aeb-8e51-4730-8f30-33a78c8f59d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0.1)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.5.0)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2023.7.22)\n",
            "Installing collected packages: loguru, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.4.2 loguru-0.7.2 pinecone-client-2.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYFNyycCQ2p-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3135211-c284-45a0-cce7-5ca742690b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "import PyPDF2\n",
        "import random\n",
        "import pinecone\n",
        "\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Working with PDF files\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1400/1*FWwgOvUE660a04zoQplS7A.png)\n",
        "\n",
        "Source: https://betterprogramming.pub/building-a-multi-document-reader-and-chatbot-with-langchain-and-chatgpt-d1864d47e339\n",
        "\n",
        "\n",
        "### 3.1 Setting up API Key"
      ],
      "metadata": {
        "id": "TwaQS_nXSQxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-XXXXXXXXXXXXX\"\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "btc16h6ySPFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Loading a PDF file\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wwNqZjc2th6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load a random PDF from a given directory\n",
        "def load_pdf(file_name):\n",
        "  return None"
      ],
      "metadata": {
        "id": "hV1ASHAHvm-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to chunk text by number of words or characters with a given size and overlap\n",
        "def chunk_text(text, chunk_size=1500, chunk_overlap=100, by='word'):\n",
        "    if by not in ['word', 'char']:\n",
        "        raise ValueError(\"Invalid value for 'by'. Use 'word' or 'char'.\")\n",
        "\n",
        "    chunks = []\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "CkrkacuNwdHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_loaded = load_pdf(\"state_of_ai_docs.pdf\")"
      ],
      "metadata": {
        "id": "NrdKL3OH97rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pcr4g7HT8GZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunk_text(pdf_loaded, by='char')"
      ],
      "metadata": {
        "id": "LfvY_eQH97o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VXEsqI1a9zbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Building RAG system (Retrieval Augmented System)"
      ],
      "metadata": {
        "id": "NH4nGGFQyvnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pinecone init"
      ],
      "metadata": {
        "id": "kJ73xZV0yvX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0xpJHnj8y57J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Building an interface to get proper answer based on the documentation\n"
      ],
      "metadata": {
        "id": "gdGX-w1CVxGx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SFhM14-NVUqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q17g6FA9CLsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C_EyZ8ibBVs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2NRakbCBc8P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}